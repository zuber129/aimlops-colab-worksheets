{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "syRBMp7ilrbe"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zuber129/aimlops-colab-worksheets/blob/main/Experimentation_Phase_1_Data_Exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Certification Programme in AI and MLOps\n",
        "## A programme by IISc and TalentSprint\n",
        "### Assignment: Research to Production Environment: Experimentation_Phase : 1. Data_Exploration & Preliminary Model\n"
      ],
      "metadata": {
        "id": "PprHHREe8n5R"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw4QHJlfsSF4"
      },
      "source": [
        "## Learning Objectives\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At the end of the experiment you will be able to:\n",
        "* Understand & explore the data \n",
        "* Perform data preprocessing\n",
        "* Apply  ML algorithms on **Titanic** dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "EsSB95vPsoxS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh70dVHx0G_B"
      },
      "source": [
        "## Dataset Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-GMJTRb0Iyy"
      },
      "source": [
        "The sinking of the Titanic is one of the most infamous shipwrecks in history.\n",
        "\n",
        "On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of many passengers and crew.\n",
        "\n",
        "While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n",
        "\n",
        "[ Data Set Link: Kaggle competition](https://www.kaggle.com/competitions/titanic)\n",
        "\n",
        "<br/>\n",
        "\n",
        "### Data Set Characteristics:\n",
        "\n",
        "**PassengerId:** Id of the passengers\n",
        "\n",
        "**Survived:** Survived or Not, information\n",
        "\n",
        "**Pclass:** Socio-economic status (SES)\n",
        "  * 1st = Upper\n",
        "  * 2nd = Middle\n",
        "  * 3rd = Lower\n",
        "\n",
        "**Name:** Surname, first names of the Passengers\n",
        "\n",
        "**Sex:** Gender of the passengers\n",
        "\n",
        "**Age:** Age of the passengers\n",
        "\n",
        "**SibSp:**\tNo. of siblings/spouse of the passenger aboard the Titanic\t\n",
        "\n",
        "**Parch:**\tNo. of parents/children of the passenger aboard the Titanic\t\n",
        "\n",
        "**Ticket:**\tTicket number\n",
        "\n",
        "**Fare:** Passenger fare\n",
        "\n",
        "**Cabin:**\tCabin number\n",
        "\n",
        "**Embarked:** Port of Embarkation\n",
        "  * S = Southampton\n",
        "  * C = Cherbourg\n",
        "  * Q = Queenstown\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Statement\n",
        "\n",
        "Build a predictive model that answers the question: “what sort of people were more likely to survive?” using titanic's passenger data (ie name, age, gender, socio-economic class, etc)."
      ],
      "metadata": {
        "id": "KmusUbENKSEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Download the datasets\n",
        "from IPython import get_ipython\n",
        "\n",
        "ipython = get_ipython()\n",
        "  \n",
        "notebook=\"U1_MH1_Data_Munging\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "    from IPython.display import HTML, display\n",
        "    ipython.magic(\"sx wget https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/titanic.csv\")\n",
        "    ipython.magic(\"sx wget https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/test_titanic.csv\")\n",
        "    print(\"Data downloaded successfully\")\n",
        "    return\n",
        "\n",
        "setup()"
      ],
      "metadata": {
        "id": "ViFc50xKK-tY",
        "cellView": "form",
        "outputId": "e05d910b-4bed-49c7-ca52-9b755f47ad34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data downloaded successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "RM8x-pMDLQuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "List of files present"
      ],
      "metadata": {
        "id": "kLVDFpbSb1ds"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** Use titanic.csv for training & testing purpose and Titanic_Test.csv for submitting the prediction on Kaggle competition."
      ],
      "metadata": {
        "id": "RKzNj9hyNNPJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gn6HQH7abkyL"
      },
      "source": [
        "## Import Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiNOMhdK5n-d"
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# to persist the model and the scaler\n",
        "import joblib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== NEW IMPORTS FOR PIPELINE BUILDING ========\n",
        "\n",
        "# pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# for the preprocessors\n",
        "from sklearn.base import BaseEstimator, TransformerMixin"
      ],
      "metadata": {
        "id": "CDA9ygWSHId4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5fBLdQaJtd4"
      },
      "source": [
        "## 1. Load & Explore the Data Set\n",
        "\n",
        "* Understand different features in the training dataset\n",
        "* Understand the data types of each columns\n",
        "* Notice the columns of missing values\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW9DMblWkhj_"
      },
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv(\"titanic.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "dyDqsnlkdbdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54ktmr8lh8AS"
      },
      "source": [
        "# Getting information about the dataset\n",
        "data.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning and Processing\n",
        "## **2. Pre-pipeline Preparation**\n"
      ],
      "metadata": {
        "id": "Gs67b6IN0xHX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### 2.1 Working on \"SibSp\" & \"Parch\" columns:\n",
        "Combine columns \"SibSp\" & \"Parch\" and create another column that represents the total passengers in one ticket with the name \"family_size\". In each ticket, there might be Siblings/Spouses (SibSp =Number of Siblings/Spouses Aboard) or Parents/Children (Parch=Number of Parents/Children Aboard ) along with the passenger who booked the ticket.\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "mUm20kyHVTZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function that takes a dataframe as a parameter and returns a transformed\n",
        "# Dataframe\n",
        "def family_size(data_frame):\n",
        "  df=data_frame.copy()\n",
        "  df['FamilySize'] = df['SibSp'] + df['Parch'] + 1 \n",
        "  return df"
      ],
      "metadata": {
        "id": "n2vHu13tWJx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=family_size(data)\n",
        "data.info()"
      ],
      "metadata": {
        "id": "lEkyLqqEVX2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pMXWDyaspe3"
      },
      "source": [
        "### 2.2 Working on \"Cabin\" column:\n",
        "Find unique entries in the Cabin column. We can label all passengers in two categories having a cabin or not. Check the data type(use: type) of each entry of the Cabin. Convert a string data type into '1' i.e. passengers with cabin and others into '0' i.e. passengers without cabin.  Write a function for the above operation and apply it to the cabin column and create another column with the name \" Has_cabin\" containing only 0 or 1 entries. \n",
        "\n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a function that takes dataframe as a parameter and returns the transformed\n",
        "# Dataframe after binary encoding of the values of 'Cabin' column\n",
        "def process_cabin(data_frame):\n",
        "  df=data_frame.copy()\n",
        "  f1=lambda x: 0 if type(x) == float else 1 ## Ternary Expression\n",
        "  df['Has_cabin']=df['Cabin'].apply(f1)\n",
        "  return df"
      ],
      "metadata": {
        "id": "KozjEOo9VS3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=process_cabin(data)\n",
        "data.info()"
      ],
      "metadata": {
        "id": "n9N82uXWWf81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Working on \"Name\" column : \n",
        "Fetch titles from the name. We can map these titles with numbers and convert them into an integer by mapping with relative numbers. Use: concept of the regular expression."
      ],
      "metadata": {
        "id": "nrMLcBqVh5yE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extracts the title (Mr, Ms, etc) from the name variable\n",
        "\n",
        "def get_title(passenger):\n",
        "    line = passenger\n",
        "    if re.search('Mrs', line):\n",
        "        return 'Mrs'\n",
        "    elif re.search('Mr', line):\n",
        "        return 'Mr'\n",
        "    elif re.search('Miss', line):\n",
        "        return 'Miss'\n",
        "    elif re.search('Master', line):\n",
        "        return 'Master'\n",
        "    else:\n",
        "        return 'Other'"
      ],
      "metadata": {
        "id": "w1uZfWxHkDPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_title('heranl Mr.')"
      ],
      "metadata": {
        "id": "VyB7sS5ykHRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Name'].apply(get_title)"
      ],
      "metadata": {
        "id": "NiiIeAPyjeqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Title'] = data['Name'].apply(get_title)"
      ],
      "metadata": {
        "id": "pPqV3McZh2-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Title'].unique()"
      ],
      "metadata": {
        "id": "1FBfCUOYoBBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "gH2xsJmW3WXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop unnecessary variables\n",
        "\n",
        "data.drop(labels=['PassengerId','Name','SibSp','Parch','Ticket','Cabin'], axis=1, inplace=True)\n",
        "\n",
        "# display data\n",
        "data.info()"
      ],
      "metadata": {
        "id": "mM2vE18w3x4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3: Data Exploration\n",
        "### Find numerical and categorical variables"
      ],
      "metadata": {
        "id": "gwMOX7o54i64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = 'Survived'"
      ],
      "metadata": {
        "id": "SjDpu_Ik4zFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of numerical columns\n",
        "vars_num = [c for c in data.columns if data[c].dtypes!='O' ]#and c!=target]\n",
        "\n",
        "# List of categorical columns\n",
        "vars_cat = [c for c in data.columns if data[c].dtypes=='O']\n",
        "\n",
        "print('Number of numerical variables: {}'.format(len(vars_num)),\":\" , vars_num)\n",
        "\n",
        "print('Number of categorical variables: {}'.format(len(vars_cat)),\":\" , vars_cat)\n"
      ],
      "metadata": {
        "id": "Pjbip-YD46CS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Find missing values in variables"
      ],
      "metadata": {
        "id": "IYDeF1iI6Ult"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first in numerical variables\n",
        "data[vars_num].isnull().mean()"
      ],
      "metadata": {
        "id": "MwM5Yxkr6PZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now in categorical variables\n",
        "data[vars_cat].isnull().mean()"
      ],
      "metadata": {
        "id": "8qkwXrOL6aJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Determine cardinality of categorical variables"
      ],
      "metadata": {
        "id": "mitBWp1h6fv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unique categories in categorical variables\n",
        "data[vars_cat].nunique()"
      ],
      "metadata": {
        "id": "q0-JItKu6gym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Determine the distribution of numerical variables"
      ],
      "metadata": {
        "id": "aqHFO3Fu6t8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a Histogram\n",
        "data[vars_num].hist(bins=30, figsize=(10,10))"
      ],
      "metadata": {
        "id": "G7INSI2j6wBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4: Split the data into train and test set\n",
        "Note: Apply all your data preprocessing steps in train set first and keep test set aside. "
      ],
      "metadata": {
        "id": "eQGya6YLOku-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=data.drop('Survived', axis=1)\n",
        "y=data['Survived']\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "mps-O7zbPPcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Feature Engineering\n",
        "\n",
        "**Numerical variables:  Age column need to fill.**"
      ],
      "metadata": {
        "id": "2yLdeB-o8kZl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1 Working on Age column :\n",
        "Find the number of NaN entries in the age column and their row index. Calculate the mean, Standard deviation of the Age column and check the distribution of the age column.We can fill the missing values with randomly generated integer values between (mean+Standard deviation, mean-Standard deviation). Use : np.isnan; np.random.randint; concept of slicing dataframe. Convert the age column as an integer data type.\n",
        "\n"
      ],
      "metadata": {
        "id": "dWmjUnN3VcF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "age_avg = X_train['Age'].mean() # Average Age\n",
        "print(\"Mean of Age :\", age_avg)\n",
        "age_std = X_train['Age'].std() # Standard Deviation\n",
        "print(\"Std of Age :\",age_std)\n",
        "age_null_count = X_train['Age'].isnull().sum() # Number of null records in this feature\n",
        "print(\"Count of Nan in Age column :\",age_null_count)\n",
        "## Plotting the histogram plot\n",
        "X_train['Age'].plot(kind='hist',bins=8,edgecolor='r')"
      ],
      "metadata": {
        "id": "gbLqDB1hVf1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function, this takes dataframe as a parameter and returns the transformed \n",
        "# Dataframe, filling the missing values of age feature as discussed above.\n",
        "def process_age(data_frame):\n",
        "  df=data_frame.copy()\n",
        "  np.random.seed(0)\n",
        "  age_avg = 29.54\n",
        "  age_std = 14.47\n",
        "  age_null_count = df['Age'].isnull().sum()\n",
        "  age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
        "  df.loc[np.isnan(df['Age']),'Age'] = age_null_random_list\n",
        "  df['Age'] = df['Age'].astype(int)\n",
        "  return df"
      ],
      "metadata": {
        "id": "MFrug-3VakhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=process_age(X_train)\n",
        "X_train.info()"
      ],
      "metadata": {
        "id": "a9a69SMpa6aG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Categorical variables:  Embarked    0.002245 column need to fill.**\n",
        "### 5.2 Working on \"Embarked\" column :\n",
        "The \"embarked\" column represents the port of Embarkation: Cherbourg(C), Queenstown(Q), and  Southampton(S ). Thus, the entries are of three categories in this column. Fill in the missing rows in this column. We can fill it with the most frequent category. Map these categorical string entries into numerical. \n",
        "\n"
      ],
      "metadata": {
        "id": "cGPgnKttVYRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.Embarked.unique()) # Unique Categories\n",
        "print(X_train.Embarked.isnull().sum()) # Number of classes\n",
        "print(X_train.Embarked.mode()) # Most frequent category"
      ],
      "metadata": {
        "id": "IApw-rL1Y1jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_embarked(data_frame):\n",
        "  df=data_frame.copy()\n",
        "  df['Embarked'] = df['Embarked'].fillna('S')\n",
        "  df['Embarked'] = df['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
        "  return df"
      ],
      "metadata": {
        "id": "rVTiJ27OVbzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=process_embarked(X_train)\n",
        "X_train.info()"
      ],
      "metadata": {
        "id": "0TFv47f9Y0yO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Encodings**"
      ],
      "metadata": {
        "id": "gMvM64L4AiEY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3 Working on \"sex\" & \"Title\" columns : \n",
        "Map the Sex column as 'female' : 0, 'male': 1, and convert it into an integer data type.\n",
        " \n",
        " "
      ],
      "metadata": {
        "id": "doeanDr0VgGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['Sex'] = X_train['Sex'].map( {'female': 0, 'male': 1} ).astype(int)"
      ],
      "metadata": {
        "id": "dGN92EsEVlTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map these categorical string entries into numerical.\n",
        "X_train['Title'] = X_train['Title'].map( {'Mrs': 4, 'Master':3 ,'Miss': 2, 'Mr': 1,'Other':0} ).astype(int)"
      ],
      "metadata": {
        "id": "HeU0RmGUksUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "id": "YVYnt5p7ccKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.4 Apply Standard Scalar"
      ],
      "metadata": {
        "id": "S2EfoVojebWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train) \n",
        "X_train_scaled[0,:]"
      ],
      "metadata": {
        "id": "fVWd4PEaeiod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.5 Create a single function for preprocessing the test set (X_test) and apply it.\n",
        "#### **Note**: All the pre-processing steps that were applied on the train set before ML Modelling are also applied on the test set before passing through the predict function."
      ],
      "metadata": {
        "id": "Kwa6Ua9Qgbi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create a function\n",
        "def pre_process(data):\n",
        "  df=data.copy()\n",
        "\n",
        "  ## working on Embarked column\n",
        "  df['Embarked'] = df['Embarked'].fillna('S')\n",
        "\n",
        "  ## Working on Age column\n",
        "  np.random.seed(0)\n",
        "  age_avg = 29.54\n",
        "  age_std = 14.47\n",
        "  age_null_count = df['Age'].isnull().sum()\n",
        "  age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
        "  df.loc[np.isnan(df['Age']),'Age'] = age_null_random_list\n",
        "  df['Age'] = df['Age'].astype(int)\n",
        "\n",
        "  ## Encoding\n",
        "  df['Sex'] = df['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
        "  df['Embarked'] = df['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
        "  # Mapping tille categorical string entries into numerical.\n",
        "  df['Title'] = df['Title'].map( {'Mrs': 4, 'Master':3 ,'Miss': 2, 'Mr': 1,'Other':0} ).astype(int)\n",
        "\n",
        "  #df.Fare=df.Fare.fillna(df.Fare.mean())\n",
        "  return df"
      ],
      "metadata": {
        "id": "RLFNNM0SgqZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Applyting above function on X_test\n",
        "x_test=pre_process(X_test)\n",
        "x_test.info()\n",
        "x_test.head()\n"
      ],
      "metadata": {
        "id": "urGx3SRcc0kN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.6 Apply standard Scalar transformation to x_test\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jlA3Gnmrc039"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_scaled = scaler.transform(x_test) ## \n",
        "x_test_scaled[0,:]"
      ],
      "metadata": {
        "id": "N0SAb9ccc2Qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 6. Apply Multiple ML Algo. & display the accuracy\n",
        "#### Expected Accuracy >= 80%\n",
        "\n",
        "#### **Random Forest**\n"
      ],
      "metadata": {
        "id": "zUMFQj-Gc1BO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model_rf = RandomForestClassifier(n_estimators=150, max_depth=5,random_state=42)"
      ],
      "metadata": {
        "id": "1Ajc0XAfdwAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_rf.fit(X_train_scaled,y_train)\n",
        "\n",
        "# Predict the model\n",
        "y_pred = model_rf.predict(x_test_scaled)\n",
        "\n",
        "# Calculate the accuracy\n",
        "print(\"Accuracy(in %):\", accuracy_score(y_test, y_pred)*100)"
      ],
      "metadata": {
        "id": "LL5TXSdxeDTh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}