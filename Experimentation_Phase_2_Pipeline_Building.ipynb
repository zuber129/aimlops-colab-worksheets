{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zuber129/aimlops-colab-worksheets/blob/main/Experimentation_Phase_2_Pipeline_Building.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Certification Programme in AI and MLOps\n",
        "## A programme by IISc and TalentSprint\n",
        "### Assignment: Research to Production Environment: Experimentation_Phase : 2. Pipeline_Building\n"
      ],
      "metadata": {
        "id": "PprHHREe8n5R"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGLbPb_LqRJd"
      },
      "source": [
        "## Learning Objectives\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At the end of the experiment you will be able to:\n",
        "* create custom classes required for processing  \n",
        "* implement pipeline and train the model\n",
        "* save the model\n",
        "\n"
      ],
      "metadata": {
        "id": "CgWeAK5kqRJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Download the datasets\n",
        "from IPython import get_ipython\n",
        "\n",
        "ipython = get_ipython()\n",
        "  \n",
        "notebook=\"U1_MH1_Data_Munging\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "    from IPython.display import HTML, display\n",
        "    ipython.magic(\"sx wget https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/titanic.csv\")\n",
        "    ipython.magic(\"sx wget https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/test_titanic.csv\")\n",
        "    print(\"Data downloaded successfully\")\n",
        "    return\n",
        "\n",
        "setup()"
      ],
      "metadata": {
        "id": "ViFc50xKK-tY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "RM8x-pMDLQuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "List of files present"
      ],
      "metadata": {
        "id": "kLVDFpbSb1ds"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNLA8HiKxQhc"
      },
      "source": [
        "### Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YzfoPvJDiTX"
      },
      "outputs": [],
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjoZJWGErxGf"
      },
      "outputs": [],
      "source": [
        "#@title Please enter your password (your registered phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WBPPuGmBlDIN"
      },
      "outputs": [],
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "\n",
        "ipython = get_ipython()\n",
        "  \n",
        "notebook= \"Experimentation_Phase_2_Pipeline_Building\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")  \n",
        "\n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "    \n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:        \n",
        "        print(r[\"err\"])\n",
        "        return None        \n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "    \n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id, \n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_mentor_support\": Mentor_support}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:        \n",
        "        print(r[\"err\"])\n",
        "        return None   \n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://aimlops-iisc.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "    \n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional: \n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional  \n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "  \n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "  \n",
        "  \n",
        "# def getWalkthrough():\n",
        "#   try:\n",
        "#     if not Walkthrough:\n",
        "#       raise NameError\n",
        "#     else:\n",
        "#       return Walkthrough\n",
        "#   except NameError:\n",
        "#     print (\"Please answer Walkthrough Question\")\n",
        "#     return None\n",
        "  \n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "  \n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError \n",
        "    else: \n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "  \n",
        "\n",
        "def getId():\n",
        "  try: \n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup \n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup() \n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gn6HQH7abkyL"
      },
      "source": [
        "## Import Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "# to persist the model and the scaler\n",
        "import joblib\n",
        "from typing import List\n",
        "# import for pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "# for the preprocessors\n",
        "from sklearn.base import BaseEstimator, TransformerMixin"
      ],
      "metadata": {
        "id": "apdU8g36rm4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Z-lTFTy7SfZ"
      },
      "source": [
        "### **1. Pre-Pipeline-Steps: Load, Explore and Prepare the Data Set** \n",
        "\n",
        "* Understand different features in the training dataset\n",
        "* Understand the data types of each columns\n",
        "* Notice the columns of missing values\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQaogC8j7SfZ"
      },
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv(\"titanic.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "t2ZjWLAK7SfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weCr4C9J7SfZ"
      },
      "source": [
        "# Getting information about the dataset\n",
        "data.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning and Processing\n"
      ],
      "metadata": {
        "id": "rGrVLftG7SfZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### 1.1 Working on \"SibSp\" & \"Parch\" columns:\n",
        "Combine columns \"SibSp\" & \"Parch\" and create another column that represents the total passengers in one ticket with the name \"family_size\". In each ticket, there might be Siblings/Spouses (SibSp =Number of Siblings/Spouses Aboard) or Parents/Children (Parch=Number of Parents/Children Aboard ) along with the passenger who booked the ticket.\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "VShR1Ils7Sfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " def family_size(data_frame):\n",
        "   df=data_frame.copy()\n",
        "   df['FamilySize'] = df['SibSp'] + df['Parch'] + 1 \n",
        "   return df"
      ],
      "metadata": {
        "id": "ibps2QaU7Sfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=family_size(data)\n",
        "data.info()"
      ],
      "metadata": {
        "id": "6yEvgF4W7Sfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwcaTE2i7Sfa"
      },
      "source": [
        "### 1.2 Working on \"Cabin\" column:\n",
        "Find unique entries in the Cabin column. We can label all passengers in two categories having a cabin or not. Check the data type(use: type) of each entry of the Cabin. Convert a string data type into '1' i.e. passengers with cabin and others into '0' i.e. passengers without cabin.  Write a function for the above operation and apply it to the cabin column and create another column with the name \" Has_cabin\" containing only 0 or 1 entries. \n",
        "\n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_cabin(data_frame):\n",
        "  df=data_frame.copy()\n",
        "  f1=lambda x: 0 if type(x) == float else 1 ## Ternary Expression\n",
        "  df['Has_cabin']=df['Cabin'].apply(f1)\n",
        "  return df"
      ],
      "metadata": {
        "id": "N3n5k0Gg7Sfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=process_cabin(data)\n",
        "data.info()"
      ],
      "metadata": {
        "id": "Q0c_akMe7Sfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3  Working on \"Name\" column : \n",
        "Fetch titles from the name. We can map these titles with numbers and convert them into an integer by mapping with relative numbers. Use: concept of the regular expression."
      ],
      "metadata": {
        "id": "w1w5zmAa7Sfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extracts the title (Mr, Ms, etc) from the name variable\n",
        "\n",
        "def get_title(passenger):\n",
        "    line = passenger\n",
        "    if re.search('Mrs', line):\n",
        "        return 'Mrs'\n",
        "    elif re.search('Mr', line):\n",
        "        return 'Mr'\n",
        "    elif re.search('Miss', line):\n",
        "        return 'Miss'\n",
        "    elif re.search('Master', line):\n",
        "        return 'Master'\n",
        "    else:\n",
        "        return 'Other'"
      ],
      "metadata": {
        "id": "TuTBLGcx7Sfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Example:\n",
        "print(get_title('Heranld Mr.'))\n",
        "data['Name'].apply(get_title)"
      ],
      "metadata": {
        "id": "hah7jtV87Sfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Title'] = data['Name'].apply(get_title)"
      ],
      "metadata": {
        "id": "EVyRV2BT7Sfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['Title'].unique())\n",
        "data.info()"
      ],
      "metadata": {
        "id": "Ov0bc38h7Sfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop unnecessary variables\n",
        "data.drop(labels=['PassengerId','Name','SibSp','Parch','Ticket','Cabin'], axis=1, inplace=True)\n",
        "\n",
        "# display data\n",
        "data.info()"
      ],
      "metadata": {
        "id": "iC9ILAYA7Sfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Pipeline-Steps**\n",
        "### Building custom class compatible with sklearn pipeline for imputation, feature mapping and any specific operation on any column. \n",
        "\n",
        "### **A. Imputation**\n",
        "\n",
        "Buiding custom Imputation class compatible with Sklearn for 'Embarked' colum imputation."
      ],
      "metadata": {
        "id": "Q1M6DZzVEvVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class embarkImputer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"embarked column imputer.\"\"\"\n",
        "\n",
        "    def __init__(self, variables: str):\n",
        "\n",
        "        if not isinstance(variables, str):\n",
        "            raise ValueError(\"variables should be a list\")\n",
        "\n",
        "        self.variables = variables\n",
        "\n",
        "    def fit(self, X: pd.DataFrame, y: pd.Series = None):\n",
        "        # we need the fit statement to accomodate the sklearn pipeline\n",
        "        self.fill_value=X[self.variables].mode()[0]\n",
        "        return self\n",
        "\n",
        "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
        "        X = X.copy()\n",
        "        X[self.variables]=X[self.variables].fillna( self.fill_value)\n",
        "\n",
        "        return X"
      ],
      "metadata": {
        "id": "RkLe65xIy5g8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.Embarked.isnull().sum()"
      ],
      "metadata": {
        "id": "UPOQY8qJ7ec9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb=embarkImputer('Embarked')\n",
        "emb.fit(data)\n",
        "print(len(emb.transform(data).Embarked))\n",
        "data1=emb.transform(data)\n",
        "print(len(data1.Embarked))\n",
        "print(data1.Embarked.isnull().sum())\n"
      ],
      "metadata": {
        "id": "9mU0joek2Bxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1.Embarked.dtypes"
      ],
      "metadata": {
        "id": "cmA-VGynVY2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1.info()"
      ],
      "metadata": {
        "id": "wKSxmZXr2_C_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **B. Mapping**\n",
        "\n",
        "Bulding Mapper class for mpping 'Embarked','Sex' and 'Title' columns"
      ],
      "metadata": {
        "id": "wv8wir4cE1sL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Mapper(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Categorical variable mapper.\"\"\"\n",
        "\n",
        "    def __init__(self, variables: str, mappings: dict):\n",
        "\n",
        "        if not isinstance(variables, str):\n",
        "            raise ValueError(\"variables should be a str\")\n",
        "\n",
        "        self.variables = variables\n",
        "        self.mappings = mappings\n",
        "\n",
        "    def fit(self, X: pd.DataFrame, y: pd.Series = None):\n",
        "        # we need the fit statement to accomodate the sklearn pipeline\n",
        "        return self\n",
        "\n",
        "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
        "        X = X.copy()\n",
        "        #for feature in self.variables:\n",
        "        X[self.variables] = X[self.variables].map(self.mappings).astype(int)\n",
        "\n",
        "        return X"
      ],
      "metadata": {
        "id": "-KVgKXzW1EcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "map_sex=Mapper('Sex',{'female': 0, 'male': 1})\n",
        "map_embarked=Mapper('Embarked', {'S': 0, 'C': 1, 'Q': 2} )\n",
        "map_title=Mapper('Title', {'Mrs': 4, 'Master':3 ,'Miss': 2, 'Mr': 1,'Other':0} )"
      ],
      "metadata": {
        "id": "AKE0XRYX8MPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1.head()"
      ],
      "metadata": {
        "id": "HriA43Xj9qr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [map_sex,map_embarked,map_title]:\n",
        "  data1=i.fit(data).transform(data1)"
      ],
      "metadata": {
        "id": "9xR9Mk3P8z3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1"
      ],
      "metadata": {
        "id": "tISsdNO49Dtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "Wkf_v2rnB330"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **C. Class for Specific operation : Age column transformation**\n",
        "\n",
        "Creating Class for Age column transformation that is compatible with SK_learn pipeline:\n",
        "\n",
        "In the pre-processing steps , a function was created for processing age column. Now we are converting that function into a class suitable for inserting inside the pipeline."
      ],
      "metadata": {
        "id": "31R3mGCtMtQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class age_col_tfr(BaseEstimator, TransformerMixin):\n",
        "  \n",
        "  \"\"\"Age column transformer\"\"\"\n",
        "\n",
        "  def __init__(self, variables):\n",
        "    \n",
        "    if not isinstance(variables, str):\n",
        "      raise ValueError('variables should be a str')\n",
        "    self.variables = variables\n",
        "\n",
        "  def fit(self, X: pd.DataFrame, y=None):\n",
        "    self.age_avg = X[self.variables].mean()\n",
        "    self.age_std = X[self.variables].std()\n",
        "      # we need this step to fit the sklearn pipeline\n",
        "    return self\n",
        "\n",
        "  def transform(self, X):\n",
        "    np.random.seed(0)\n",
        "    X = X.copy() # so that we do not over-write the original dataframe\n",
        "    age_null_count = X[self.variables].isnull().sum()\n",
        "    age_null_random_list = np.random.randint(self.age_avg - self.age_std, self.age_avg + self.age_std, size=age_null_count)\n",
        "    X.loc[np.isnan(X[self.variables]),self.variables] = age_null_random_list\n",
        "    X[self.variables] = X[self.variables].astype(int)\n",
        "    return X\n"
      ],
      "metadata": {
        "id": "F3X7hC0kiEye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "age_tfr=age_col_tfr('Age')"
      ],
      "metadata": {
        "id": "3sv3ZDdLWz4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "age_tfr.fit(data1)"
      ],
      "metadata": {
        "id": "e4f8JLbJW8_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1=age_tfr.transform(data1)"
      ],
      "metadata": {
        "id": "zdzJw-CvXa7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(data1.Age.isnull())"
      ],
      "metadata": {
        "id": "L-bkS6Kviej2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Building Pipeline**\n",
        "\n",
        "Finally building pipeline and implementing all above class inside pipeline along with classifier also inside."
      ],
      "metadata": {
        "id": "JdJMvVo7T8G9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_pipe=Pipeline([\n",
        "    \n",
        "    ('embark_imputation', embarkImputer(variables='Embarked')),\n",
        "    ##==========Mapper======##\n",
        "     ('map_sex',Mapper('Sex',{'female': 0, 'male': 1})),\n",
        "      ('map_embarked',Mapper('Embarked', {'S': 0, 'C': 1, 'Q': 2} )),\n",
        "       ('map_title',Mapper('Title', {'Mrs': 4, 'Master':3 ,'Miss': 2, 'Mr': 1,'Other':0})),\n",
        "    \n",
        "     # Transformation of age column\n",
        "    ('age_transform', age_col_tfr(variables='Age')),\n",
        "\n",
        "    # scale\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model_rf', RandomForestClassifier(n_estimators=150, max_depth=5,random_state=42))\n",
        "])"
      ],
      "metadata": {
        "id": "MeqaEIn-lMdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train_test_split"
      ],
      "metadata": {
        "id": "RyrrJ0vwseox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=data.drop('Survived', axis=1)\n",
        "y=data['Survived']\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "-pV4ja6Dse-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_pipe.fit(X_train,y_train)\n",
        "y_pred=titanic_pipe.predict(X_test)\n",
        "# Calculate the accuracy\n",
        "print(\"Accuracy(in %):\", accuracy_score(y_test, y_pred)*100)"
      ],
      "metadata": {
        "id": "4x6Ctgrslpw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Persist the model"
      ],
      "metadata": {
        "id": "xgvhU3rRK1px"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(titanic_pipe,'titanic_pip.joblib')"
      ],
      "metadata": {
        "id": "ilfd93a7K0-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking for the versions may be used for requirements.txt file"
      ],
      "metadata": {
        "id": "e2tWS2-0q0gA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import pydantic\n",
        "import joblib"
      ],
      "metadata": {
        "id": "PBWmi8KrrDVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pydantic"
      ],
      "metadata": {
        "id": "-FYdEP5ebySl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install strictyaml"
      ],
      "metadata": {
        "id": "WlszwqBUbLig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ruamel.yaml"
      ],
      "metadata": {
        "id": "7luGjUorbaDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import strictyaml"
      ],
      "metadata": {
        "id": "hnMjBIEobO3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ruamel.yaml\n"
      ],
      "metadata": {
        "id": "kVJtspNLbffK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.__version__)\n",
        "print(pd.__version__)\n",
        "print(sklearn.__version__)\n",
        "print(pydantic.__version__)\n",
        "print(strictyaml.__version__)\n",
        "print(ruamel.yaml.__version__)\n",
        "print(joblib.__version__)"
      ],
      "metadata": {
        "id": "MvuHtoy4sSgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHfHdGCP_n6Y"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgSwVENIPcM6"
      },
      "outputs": [],
      "source": [
        "#@title  In the final pipeline, in the notebook, what happens while applying the 'train' and 'predict' methods? **Train:** It learns parameters viz. mean, standard deviation, and others as per the transformer classes along with trained weights and biases via ML model, using the dataset passed as an argument. **Predict:** It applies those parameters learned from the dataset used in the 'train' method and transforms the dataset passed inside the 'predict' method. After transformation, it applies the 'predict' method from the ML model. {run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer = \" \" #@param [\" \", \"True\", \"False\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMzKSbLIgFzQ"
      },
      "outputs": [],
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjcH1VWSFI2l"
      },
      "outputs": [],
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"\" #@param {type:\"string\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VBk_4VTAxCM"
      },
      "outputs": [],
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XH91cL1JWH7m"
      },
      "outputs": [],
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8xLqj7VWIKW"
      },
      "outputs": [],
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FzAZHt1zw-Y-"
      },
      "outputs": [],
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ]
    }
  ]
}