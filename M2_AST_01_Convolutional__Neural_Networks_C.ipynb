{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zuber129/aimlops-colab-worksheets/blob/main/M2_AST_01_Convolutional__Neural_Networks_C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Certification Programme in AI and MLOps\n",
        "## A programme by IISc and TalentSprint\n",
        "### Assignment: CNN - MNIST, Cats & Dogs"
      ],
      "metadata": {
        "id": "PprHHREe8n5R"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-1SXdIFtYAY"
      },
      "source": [
        "## Learning Objectives:\n",
        "\n",
        "At the end of the experiment, you will be able to:\n",
        "\n",
        "1. Understand Conv2D and MaxPooling layers used in ConVNet\n",
        "2. Build a simple ConvNet for image classification using the digit MNIST dataset\n",
        "3. Build another  ConvNet for  image Classification using the cats-and-dogs dataset\n",
        "4. Apply Data Augmentation\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUgk-iFZtjTA"
      },
      "source": [
        "## 1. Building a simple CNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyPJgDl1mFWD"
      },
      "source": [
        "Let's start with a simple example. We will\n",
        "1. Build a CNN with convolution and pooling layers\n",
        "2. Train it on the MNIST dataset\n",
        "\n",
        "The figure below is a typical ConvNet (LeNet) architecture that we are going to build but with different numbers and sizes of filters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFRlXH4XvD28"
      },
      "source": [
        "![picture](https://drive.google.com/uc?export=view&id=1vT8e59AYTFRlrrI3C-iUHTctxyhfBiJJ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNLA8HiKxQhc"
      },
      "source": [
        "### Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YzfoPvJDiTX"
      },
      "outputs": [],
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"2237305\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjoZJWGErxGf"
      },
      "outputs": [],
      "source": [
        "#@title Please enter your password (your registered phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBPPuGmBlDIN",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook= \"M2_AST_01_Convolutional_Neural_Networks_C\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "\n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "\n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id,\n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_mentor_support\": Mentor_support}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://aimlops-iisc.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "\n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "\n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "# def getWalkthrough():\n",
        "#   try:\n",
        "#     if not Walkthrough:\n",
        "#       raise NameError\n",
        "#     else:\n",
        "#       return Walkthrough\n",
        "#   except NameError:\n",
        "#     print (\"Please answer Walkthrough Question\")\n",
        "#     return None\n",
        "\n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getId():\n",
        "  try:\n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup\n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Data\n",
        "!wget -qq https://cdn.iisc.talentsprint.com/AIandMLOps/Datasets/housing_dataset.csv\n",
        "print(\"Data downloaded successfully!\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kBINTxv0O26H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "5IqJs6tAUX10"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eMODYdFtKeR"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "bDEevleAzCi4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCr4POjiAI4L"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "print(f\"train_images.shape = {train_images.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reshape and convert to float"
      ],
      "metadata": {
        "id": "0XPQ7HdyzJTq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vWWJnvaAPOY"
      },
      "outputs": [],
      "source": [
        "# Reshape and convert to float\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)) # Q: How many samples do we have? A: 60000\n",
        "train_images = train_images.astype(\"float32\") / 255 # Q: Why are we dividing by 255? A: To rescale data to lie in [0,1]\n",
        "print(f\"train_images.shape = {train_images.shape}\")\n",
        "\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype(\"float32\") / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRqPDv_UvQHl"
      },
      "source": [
        "### Building the architecture\n",
        "LeNet-5: Example of an early ConvNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCD1Mta9twxU"
      },
      "outputs": [],
      "source": [
        "# Define convnet\n",
        "# Q: Which API are we using? A: Functional API\n",
        "inputs = keras.Input(shape=(28, 28, 1))     # Q: How many channels does the input image have? A: 1\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)  # Q: Meaning of each argument?\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)             # Q: What is the height and width of feature maps after this layer? A: 13x13\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(x)  # Need Dense layer at the end for classification\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEJymG4Wty8d"
      },
      "outputs": [],
      "source": [
        "model.summary()\n",
        "# Q: Verify no. of params in 1st conv layer # A: (3X3X1 + 1) X 32 ; 32 filters, 9 weights per kernel, 1 bias ber kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yrrx-MY0ASp6"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",     # Q: Why sparse_cat_crossent?  A: labels are not one-hot-encoded\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Call Back Function"
      ],
      "metadata": {
        "id": "gAY7NwrZM81q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRjznrJmvYwE"
      },
      "outputs": [],
      "source": [
        "# Define a function to return a commmonly used callback_list\n",
        "def def_callbacks(filepath, mod_chk_mon = \"val_loss\", tensorboard = True, earlystop = 0 ):\n",
        "    callback_list = []\n",
        "\n",
        "    # Defualt callback\n",
        "    callback_list.append(keras.callbacks.ModelCheckpoint(filepath,\n",
        "                                         save_best_only = True,\n",
        "                                         monitor=mod_chk_mon))\n",
        "    if tensorboard:\n",
        "      log_dir = \"tensorLog_\" + filepath\n",
        "      callback_list.append(keras.callbacks.TensorBoard(log_dir=log_dir))\n",
        "\n",
        "    if earlystop>0:\n",
        "       callback_list.append(keras.callbacks.EarlyStopping(patience=earlystop))\n",
        "\n",
        "    return callback_list"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training & Evaluation"
      ],
      "metadata": {
        "id": "9PCMqHhuNSTL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ai9XQpACty-j"
      },
      "outputs": [],
      "source": [
        "PARTIAL_RUN = False\n",
        "epochs = 10\n",
        "if PARTIAL_RUN:\n",
        "  epochs = 2\n",
        "model.fit(train_images, train_labels, epochs=epochs, validation_split=0.2, batch_size=64, callbacks=def_callbacks(\"prob1\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction on test data"
      ],
      "metadata": {
        "id": "2mGU00hTzSwi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlntfyEptgt7"
      },
      "outputs": [],
      "source": [
        "# Evaluate test accuracy\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)  # Q: Which state is this model at? A: Slightly overfit, trained till 10th epoch\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhYHKrIdp6uV"
      },
      "source": [
        "Nearly **99%** accurate! This is much better than what we achieved with our feedforward network with only dense layers!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensorboard results"
      ],
      "metadata": {
        "id": "kHpzRTyiN42w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MKhO_2SpSLj"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/tensorLog_prob1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5yJg1wnqgKQ"
      },
      "source": [
        "### Now, let's see the importance of pooling layers.\n",
        "\n",
        "We will make a new model called 'model_no_max_pool' without any pooling layers and compare it with the previous model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6z0UF_TvBSr"
      },
      "outputs": [],
      "source": [
        "# Define a new convnet without any pooling layers\n",
        "inputs = keras.Input(shape=(28, 28, 1))\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "model_no_max_pool = keras.Model(inputs=inputs, outputs=outputs)\n",
        "# Q: Do you expect more/less no. of trainable params? A: More number of params because of lager no. of neurons before the dense layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaKi96I7va-d"
      },
      "outputs": [],
      "source": [
        "model_no_max_pool.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jj1tUASrPs4"
      },
      "source": [
        "#### Observations from models with and without pooling layers\n",
        "1. The initial model with pooling layers had just 104,202 parameters but the model without pooling layers (model_no_max_pool) has 712,202 parameters i.e. increase in the number of trainable parameters. **Model with pooling layer is less prone to overfitting** due to a smaller number of parameters/weights.\n",
        "\n",
        "2. What other advantage does the pooing layer provide? **They facilitate learning a spatial hierarchy of features**.\n",
        "\n",
        "  In the CNN given below. Imagine a 1x1 patch on a C3 feature map. It contains information from 6x6 window of the input layer. On the other hand, if no pooling layers are present, then it would contain information from a 3x3 window in the input layer.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_O5B2701vd44"
      },
      "source": [
        "![picture](https://drive.google.com/uc?export=view&id=1vT8e59AYTFRlrrI3C-iUHTctxyhfBiJJ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Cis1mDCvutX"
      },
      "source": [
        "**Optional Exercise:** Train the model_no_max_pool\n",
        " with the MNIST data set and compare its accuracy with the first model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6LzAYhovfuC"
      },
      "source": [
        "**In class exercise:** Let's try to build a LeNet-5 architecure as given in above diagram right now:\n",
        "\n",
        "\n",
        "* 1st Conv and 2nd Conv layers have a 3x3 & 5x5 kernel respectively\n",
        "* Pooling layers have 2x2 kernel\n",
        "* All activations as 'relu' except for last\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhASzPTavccH"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(28,28 , 1))\n",
        "x = layers.Conv2D(filters= 6, kernel_size= 3, padding= 'same',  activation='relu')(inputs)  # xxx is an argument\n",
        "x = layers.MaxPooling2D(pool_size= 2)(x)             # infer from diagram\n",
        "x = layers.Conv2D(filters= 16, kernel_size= 5, padding='valid' , activation='relu')(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(120, activation='relu')(x)\n",
        "x = layers.Dense(84, activation='relu')(x)\n",
        "outputs = layers.Dense(10, activation='softmax')(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syM6r3KAwLRb"
      },
      "source": [
        "## 2. Image Classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrqghDRkvDAh"
      },
      "source": [
        "Now, we know how to build a simple CNN, let's build and train one to solve an image classification problem.\n",
        "\n",
        "We will work with the cats-vs-dogs dataset to classify whether a given image is that of a cat or a dog .i.e a  binary classification problem."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries"
      ],
      "metadata": {
        "id": "gLFh-pFLUdpK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XelqVXc1wRv8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import image_dataset_from_directory"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have already uploaded the dataset into structured folders. You simply need to download it from our repository."
      ],
      "metadata": {
        "id": "zCNRgUsjdd6U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyM-hyYSkiu0",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Download the data\n",
        "!wget -qq https://cdn.iisc.talentsprint.com/AIandMLOps/Datasets/cats_vs_dogs_small.zip\n",
        "!unzip -qq '/content/cats_vs_dogs_small.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUfhxMyOkrA2"
      },
      "outputs": [],
      "source": [
        "# defining path names for futur use\n",
        "data_dir = '/content/cats_vs_dogs_small'\n",
        "\n",
        "train_path = data_dir + '/train'\n",
        "validation_path = data_dir + '/validation'\n",
        "test_path = data_dir + '/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V71xYZDRlL_E"
      },
      "outputs": [],
      "source": [
        "# Visualise the original data\n",
        "dog_image = train_path + '/dog/' +  'dog.443.jpg'\n",
        "print(\"shape of the dog image is:\",imread(dog_image).shape)\n",
        "plt.imshow(imread(dog_image))\n",
        "\n",
        "dim1 = []\n",
        "dim2 = []\n",
        "\n",
        "for image_file in os.listdir(train_path+'/dog'):\n",
        "    img = imread(train_path +'/dog/'+image_file)\n",
        "    d1,d2,colour_channels = img.shape\n",
        "    dim1.append(d1)\n",
        "    dim2.append(d2)\n",
        "\n",
        "sns.jointplot((dim1,dim2))\n",
        "print(\"Mean across height of all dog images in train set is:\",np.mean(dim1))\n",
        "print(\"Mean across width of all dog images in train set is:\",np.mean(dim2))\n",
        "# Q: Do all the images in the dataset have the same sizes? A: No"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3FyIB1gyqXg"
      },
      "source": [
        "### Converting the image dataset into a workable format\n",
        "\n",
        "We have the images in folders. We need to make it into a workable dataset:\n",
        "  * Which has labels\n",
        "  * All the images have the same size\n",
        "\n",
        "For this, we will use the utility [**image_dataset_from_directory**](https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory).\n",
        "\n",
        "Calling image_dataset_from_directory(main_directory, labels='inferred') will return a tf.data.Dataset that yields batches of images from the subdirectories class_a and class_b, together with labels 0 and 1 (0 corresponding to class_a and 1 corresponding to class_b)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVOWgUhECt5d"
      },
      "outputs": [],
      "source": [
        "train_dataset = image_dataset_from_directory(\n",
        "               train_path,\n",
        "                image_size=(180, 180), # Resize the images to (180,180)\n",
        "                batch_size=32)\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "                      validation_path,\n",
        "                      image_size=(180, 180),\n",
        "                      batch_size=32)\n",
        "test_dataset = image_dataset_from_directory(\n",
        "                test_path,\n",
        "                image_size=(180, 180),\n",
        "                batch_size=32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_UlcX7j7c8J"
      },
      "outputs": [],
      "source": [
        "print(f\"train_dataset = {train_dataset}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISmvr0Zx2-fP"
      },
      "outputs": [],
      "source": [
        "# Verify batch size\n",
        "for data_batch, labels_batch in train_dataset:\n",
        "  print(\"data batch shape:\", data_batch.shape)\n",
        "  print(\"labels batch shape:\", labels_batch.shape)\n",
        "  break\n",
        "# Q: What is the batch size of each mini-batch? A: 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuo-mdPJ1nM8"
      },
      "outputs": [],
      "source": [
        "# Define covnet model\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)  # Rescale input to lie between 0 and 1\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # Q: Why sigmoid? A: Binary classification\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2FDkJSc1uTm"
      },
      "outputs": [],
      "source": [
        "# compile the model\n",
        "model.compile(loss=\"binary_crossentropy\",   # Q: Why binary_crossentropy? A: Binary classification\n",
        "                      optimizer=\"rmsprop\",\n",
        "                      metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_vp34qM4Jlh"
      },
      "outputs": [],
      "source": [
        "# fit the model\n",
        "PARTIAL_RUN = False\n",
        "epochs = 10\n",
        "if PARTIAL_RUN:\n",
        "  epochs = 2\n",
        "history = model.fit(train_dataset,epochs=epochs,validation_data=validation_dataset,callbacks=def_callbacks(\"convnet_from_scratch.keras\"))\n",
        "## Using a previously defined callback function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Z29iTD0imOa"
      },
      "outputs": [],
      "source": [
        "test_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVu3QoyP4L9y"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/tensorLog_convnet_from_scratch.keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFwCvzcJ1JK6"
      },
      "source": [
        "Great! From just **2000** images, our network has learnt to classify images of cats and dogs with an accuracy of apx **70%**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQqCNE1H8IRf"
      },
      "source": [
        "## 3. Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMU298TB2XiY"
      },
      "source": [
        "The small dataset can cause a high variance estimation of model performance\n",
        "\n",
        "Q: How to overcome this and get a more robust model?\n",
        "\n",
        "Now, we want to avoid this problem altogether by artificially (and cleverly) producing new data from the already available data.\n",
        "\n",
        "For this, we perform **data augmentation**.\n",
        "\n",
        "Data augmentation is another regularization method. What other methods did we see in the last tutorial?\n",
        "\n",
        "Data augmentation takes the approach of generating more training data from existing training samples by augmenting the samples via a number of random transformations that yield a believable-looking image. Common transformations include:\n",
        "  * Flipping the image\n",
        "  * Rotating the image\n",
        "  * Zooming in/out of the image\n",
        "\n",
        "See some sample images below after augmentation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OANl64VG5vCI"
      },
      "source": [
        "![picture](https://drive.google.com/uc?export=view&id=1HRhsHEHtcVptNVMF1EbCGiZX5XuTdrs5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gRMWTEGhNQk"
      },
      "outputs": [],
      "source": [
        "# Performing the data augmentation as series of transformations\n",
        "def get_data_augmented(flip=\"horizontal\",rotation=0.1,zoom=0.2):\n",
        "    data_augmentation = keras.Sequential([\n",
        "      keras.layers.RandomFlip(flip),\n",
        "      keras.layers.RandomRotation(rotation),\n",
        "      keras.layers.RandomZoom(zoom)])\n",
        "    return data_augmentation\n",
        "# Q: what does the above function return? A: A sequence of layers\n",
        "\n",
        "data_augmentation = get_data_augmented()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fftU_EPahV48"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "# Augmenting data - Transformations of images by random factors\n",
        "# so the the network never sees the same data twice\n",
        "x = data_augmentation(inputs)\n",
        "x = layers.Rescaling(1./255)(x)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.5)(x)     # Q: Dropout is a _______ method\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHYpxJ5IhdFj"
      },
      "outputs": [],
      "source": [
        "PARTIAL_RUN = False\n",
        "epochs = 80\n",
        "if PARTIAL_RUN:\n",
        "  epochs = 2\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=def_callbacks(\"convnet_from_scratch_with_augmentation_keras\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akGYcQxOiQ7m"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/tensorLog_convnet_from_scratch_with_augmentation_keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LAK18JWiwNO"
      },
      "outputs": [],
      "source": [
        "test_model = keras.models.load_model(\n",
        "            \"convnet_from_scratch_with_augmentation_keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU64Kt9J7Ha4"
      },
      "source": [
        "With data augmentation, we roughly get **82-85%** accuracy. This is a big improvement over the previous approach, where we got roughly 70% accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHfHdGCP_n6Y"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgSwVENIPcM6"
      },
      "outputs": [],
      "source": [
        "#@title  We are applying 2 convolution filters of size 3X3 on an image of a size 6X6 Pixel having 3 channels. What is the shape of the output after the convolution operation and what is the number of parameters including bias? Given, no padding and stride is one. {run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer = \"\" #@param [\"\", \"(4X4X2); 56\", \"(3X3X2); 20\", \"(3X3X2); 56\", \"(4X4X2); 20\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMzKSbLIgFzQ"
      },
      "outputs": [],
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjcH1VWSFI2l"
      },
      "outputs": [],
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"\" #@param {type:\"string\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VBk_4VTAxCM"
      },
      "outputs": [],
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XH91cL1JWH7m"
      },
      "outputs": [],
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8xLqj7VWIKW"
      },
      "outputs": [],
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FzAZHt1zw-Y-"
      },
      "outputs": [],
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}